{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPP Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JejiUxS-w8ce"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All loans to Georgia businesses that remain in the PPP database (ppp_applicants_ga_full.csv)"
      ],
      "metadata": {
        "id": "rFTFizL-xb6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "filepath = \"ppp_applicants_ga_full.csv\"\n",
        "data = pd.read_csv(filepath)\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "mkXwfpSGw98u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "na = df.isna().any()\n",
        "NA_columns = df.columns[na].tolist()\n",
        "NA_columns"
      ],
      "metadata": {
        "id": "rR0dAJqVw96h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the data (numerical variables)\n",
        "df.describe(include=[np.number])"
      ],
      "metadata": {
        "id": "K70532tuw94L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the data (categorical variables)\n",
        "df.describe(include=[object])"
      ],
      "metadata": {
        "id": "M_q9dMOUw91t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct the data type: numerical to categorical\n",
        "df.naics_code = df.naics_code.apply(str)\n",
        "df.loan_number = df.loan_number.apply(str)\n",
        "df.sba_office_code = df.sba_office_code.apply(str)\n",
        "df.servicing_lender_location_id = df.servicing_lender_location_id.apply(str)\n",
        "df.originating_lender_location_id = df.originating_lender_location_id.apply(str)"
      ],
      "metadata": {
        "id": "5Wbc01KYw9zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Address the NA values\n",
        "df.undisbursed_amount = df.undisbursed_amount.fillna(0)\n",
        "df[df.project_county_name.isna()] # find the observations records of the NA value\n",
        "df.project_county_name.fillna(\"LEE\", limit = 1, inplace = True) # observation 39150: project_county_name = LEE\n",
        "df.project_county_name.fillna(\"FULTON\", limit = 1, inplace = True) # observation 88268: project_county_name = FULTON\n",
        "df.project_county_name.fillna(\"COBB\", limit = 1, inplace = True) # observation 177572: project_county_name = COBB\n",
        "df.project_county_name.fillna(\"COLQUITT\", limit = 1, inplace = True) # observation 239504: project_county_name = COLQUITT\n",
        "df.project_county_name.fillna(\"GWINNETT\", limit = 1, inplace = True) # observation 279180: project_county_name = GWINNETT\n",
        "df.project_county_name.fillna(\"COBB\", limit = 1, inplace = True) # observation 396988: project_county_name = COBB"
      ],
      "metadata": {
        "id": "UP6qVPxYw9xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop name\n",
        "df = df.drop(columns=\"name\", axis=1)\n",
        "\n",
        "# Drop forgiveness_amount\n",
        "df = df.drop(columns=\"forgiveness_amount\", axis=1)\n",
        "\n",
        "# Drop forgiveness_data\n",
        "df = df.drop(columns=\"forgiveness_date\", axis=1)"
      ],
      "metadata": {
        "id": "t26C7I2ow9uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loans to Georgia businesses that were removed from the PPP database (ppp-removed-ga.xlsx)"
      ],
      "metadata": {
        "id": "BGXRGaWTxgOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "filepath1 = \"ppp-removed-ga.xlsx\"\n",
        "data1 = pd.read_excel(filepath1)\n",
        "df1 = pd.DataFrame(data1)"
      ],
      "metadata": {
        "id": "A6a6TN_Ow9sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Prepocessing\n",
        "na1 = df1.isna().any() \n",
        "NA_columns1 = df1.columns[na1].tolist()\n",
        "NA_columns1"
      ],
      "metadata": {
        "id": "9CZ9XLGVw9pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of loan_status_date\n",
        "df1.loan_status_date.describe()"
      ],
      "metadata": {
        "id": "YSBLyzJVw9no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the data (numerical variables)\n",
        "df1.describe(include=[np.number])"
      ],
      "metadata": {
        "id": "fZBOiS1jw9lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the data (categorical variables)\n",
        "df1.describe(include=[object])"
      ],
      "metadata": {
        "id": "OnCnjuGow9i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct the data type: numerical to categorical\n",
        "df1.naics_code = df1.naics_code.apply(str)\n",
        "df1.loan_number = df1.loan_number.apply(str)\n",
        "df1.sba_office_code = df1.sba_office_code.apply(str)\n",
        "df1.servicing_lender_location_id = df1.servicing_lender_location_id.apply(str)\n",
        "df1.originating_lender_location_id = df1.originating_lender_location_id.apply(str)\n",
        "df1.forgiveness_date = df1.forgiveness_date.apply(str)"
      ],
      "metadata": {
        "id": "ybNowGlew9gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Address the NA values\n",
        "df1.undisbursed_amount = df1.undisbursed_amount.fillna(0)\n",
        "df1 = df1.drop(columns=\"name\" ,axis=1)\n",
        "df1 = df1.drop(columns=\"forgiveness_amount\" ,axis=1)\n",
        "df1 = df1.drop(columns=\"forgiveness_date\" ,axis=1)"
      ],
      "metadata": {
        "id": "A-BXYYU6w9ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the variable \"Removed\"\n",
        "df[\"removed\"] = 0\n",
        "df1[\"removed\"] = 1"
      ],
      "metadata": {
        "id": "Io2tvH3fw9cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save datasets to new excel files\n",
        "df.to_csv('new_ppp_applicants_ga_full.csv')\n",
        "df1.to_excel('new_ppp-removed-ga.xlsx')"
      ],
      "metadata": {
        "id": "e1uai6gXw9aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the saved data set\n",
        "filepath_new_all = \"new_combined_data.csv\"\n",
        "data_new_all = pd.read_csv(filepath_new_all)\n",
        "df_new_all = pd.DataFrame(data_new_all)"
      ],
      "metadata": {
        "id": "XJdbNaIaw9Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Address missing values\n",
        "df_new_all.naics_code = df_new_all.naics_code.fillna(\"None\")\n",
        "df_new_all.business_type = df_new_all.business_type.fillna(\"None\")\n",
        "df_new_all.loan_status_date = df_new_all.loan_status_date.fillna(\"Other\")"
      ],
      "metadata": {
        "id": "uHsNciSrw9VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Cohen's d function\n",
        "def cohen(sample_1, sample_2):\n",
        "  return (mean(sample_1) - mean(sample_2)) / (sqrt((stdev(sample_1) ** 2 + stdev(sample_2) ** 2) / 2))"
      ],
      "metadata": {
        "id": "ucHAXCHox1mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare variables to calculate Cohen's d\n",
        "df_fl = df_new_all.loc[df_new_all[\"removed\"] == 0]\n",
        "df_rm = df_new_all.loc[df_new_all[\"removed\"] == 1]\n",
        "df_fl[\"amount_per_job\"] = df_fl.amount / df_fl.jobs_retained\n",
        "df_rm[\"amount_per_job\"] = df_rm.amount / df_rm.jobs_retained\n",
        "lmi_num_fl = pd.Series(np.searchsorted(['N', 'Y'], df_fl.lmi_indicator), df_fl.index)\n",
        "lmi_num_rm = pd.Series(np.searchsorted(['N', 'Y'], df_rm.lmi_indicator), df_rm.index)\n",
        "RU_num_fl = pd.Series(np.searchsorted(['R', 'U'], df_fl.rural_urban_indicator), df_fl.index)\n",
        "RU_num_rm = pd.Series(np.searchsorted(['R', 'U'], df_rm.rural_urban_indicator), df_rm.index)\n",
        "hub_num_fl = pd.Series(np.searchsorted(['N', 'Y'], df_fl.hubzone_indicator), df_fl.index)\n",
        "hub_num_rm = pd.Series(np.searchsorted(['N', 'Y'], df_rm.hubzone_indicator), df_rm.index)\n",
        "job_noSP_fl = df_fl[df_fl.business_type != \"Sole Proprietorship\"]\n",
        "job_noSP_fl = job_noSP_fl[job_noSP_fl.business_type != \"Self-Employed Individuals\"]\n",
        "job_noSP_rm = df_rm[df_rm.business_type != \"Sole Proprietorship\"]\n",
        "job_noSP_rm = job_noSP_rm[job_noSP_rm.business_type != \"Self-Employed Individuals\"]"
      ],
      "metadata": {
        "id": "0FJxjtz1x1kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Cohen's d\n",
        "print(\"The effect sample size for LMI indicator is\",cohen(lmi_num_fl, lmi_num_rm))\n",
        "print(\"The effect sample size for Rural Urban indicator is\", cohen(RU_num_fl, RU_num_rm))\n",
        "print(\"The effect sample size for Hubzone indicator is\", cohen(hub_num_fl, hub_num_rm))\n",
        "print(\"The effect sample size for amount is\", cohen(df_fl.amount, df_rm.amount))\n",
        "print(\"The effect sample size for amount per jobs retained is\", cohen(df_fl.amount_per_job[df_fl.jobs_retained != 0], df_rm.amount_per_job[df_rm.jobs_retained != 0]))\n",
        "print(\"The effect sample size for term\", cohen(df_fl.term, df_rm.term))\n",
        "print(\"The effect sample size for jobs retained\", cohen(df_fl.jobs_retained, df_rm.jobs_retained))\n",
        "print(\"The effect sample size for approval amount difference\", cohen(df_fl.current_approval_amount - df_fl.initial_approval_amount, df_rm.current_approval_amount - df_rm.initial_approval_amount))\n",
        "print(\"The effect sample size for jobs retained without sole proprietorship and self-employed individuals\", cohen(job_noSP_fl.jobs_retained, job_noSP_rm.jobs_retained))"
      ],
      "metadata": {
        "id": "8eqplBN0x1iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Analysis\n",
        "df_new_all_corr = df_new_all\n",
        "df_new_all_corr.drop([\"sba_office_code\", \"term\", \"sba_guaranty_percentage\", \"servicing_lender_location_id\", \"originating_lender_location_id\", \"Unnamed: 0\", \"naics_code\", \"loan_number\", \"removed\"], axis = 1, inplace = True)\n",
        "corr = df_new_all_corr.corr()\n",
        "mask = np.triu(np.ones_like(corr, dtype = bool))\n",
        "cmap = sn.diverging_palette(230, 20, as_cmap = True)\n",
        "plt.show(sn.heatmap(corr, mask = mask, cmap = cmap, vmax = 1, vmin= -1, center = 0, annot = True, \n",
        "            square = True, linewidths = .3, cbar_kws = {\"shrink\": .5}, fmt='.2f'))"
      ],
      "metadata": {
        "id": "JgmAEp96x1gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop variables, and test 19 different models\n",
        "df = df_new_all.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\", \"address\", \"city\", \"zip\", \"date_approved\", \"congressional_district\", \"loan_number\", \"servicing_lender_location_id\", \"servicing_lender_address\", \"servicing_lender_city\", \"servicing_lender_zip\", \"project_city\", \"project_county_name\", \"project_zip\", \"originating_lender_city\", \"loan_status_date\", \"originating_lender_location_id\"] ,axis=1)\n",
        "df1 = df_new_all.drop(columns=\"naics_code\", axis=1) \n",
        "df2 = df1.drop(columns=\"processing_method\", axis=1) \n",
        "df3 = df2.drop(columns=\"lender\", axis=1) \n",
        "df5 = df3.drop(columns=\"rural_urban_indicator\", axis=1) \n",
        "df6 = df5.drop(columns=\"lmi_indicator\", axis=1) \n",
        "df7 = df6.drop(columns=\"servicing_lender_state\", axis=1)  \n",
        "df8 = df7.drop(columns=\"project_state\", axis=1) \n",
        "df9 = df8.drop(columns=\"sba_office_code\", axis=1) \n",
        "df10 = df9.drop(columns=\"servicing_lender_name\", axis=1) \n",
        "df11 = df10.drop(columns=\"originating_lender_state\", axis=1) \n",
        "df12 = df11.drop(columns=\"hubzone_indicator\", axis=1) \n",
        "df13 = df13.drop(columns=\"current_approval_amount\", axis=1) \n",
        "df14 = df15.drop(columns=\"initial_approval_amount\", axis=1) \n",
        "df15 = df16.drop(columns=\"sba_guaranty_percentage\", axis=1) \n",
        "df16 = df17.drop(columns=\"jobs_retained\", axis=1) \n",
        "df17 = df19.drop(columns=\"amount\", axis=1) \n",
        "df18 = df20.drop(columns=\"loan_status\", axis=1)"
      ],
      "metadata": {
        "id": "8WLoV9Wix1dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dummies\n",
        "dm = pd.get_dummies(df21, drop_first=True)"
      ],
      "metadata": {
        "id": "djYaocQryE5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data patitioning"
      ],
      "metadata": {
        "id": "cx84J5L6ybyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the target variable\n",
        "target = dm.removed\n",
        "\n",
        "# Set the independent variables\n",
        "indep_data = dm.drop(columns=\"removed\", axis=1)\n",
        "\n",
        "# Split the data and target into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "data_train, data_valid, target_train, target_valid = train_test_split(indep_data, target, test_size=0.3, random_state=50)"
      ],
      "metadata": {
        "id": "WjO8h5u5yE3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(data_train,target_train)\n",
        "\n",
        "# Prediction\n",
        "logreg.predict(data_valid)\n",
        "print(\"Independent variables in model = %s\" % data_train.columns.tolist())"
      ],
      "metadata": {
        "id": "7I-BotDWyE1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
        "print(\"Accuracy for training = %.2f\" % accuracy_score(target_train, logreg.predict(data_train)))\n",
        "print(\"Accuracy for validation = %.2f\" % accuracy_score(target_valid, logreg.predict(data_valid)))"
      ],
      "metadata": {
        "id": "9h8VL5jVyhr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion model\n",
        "print(confusion_matrix(target_train, logreg.predict(data_train)))\n",
        "print(confusion_matrix(target_valid, logreg.predict(data_valid)))"
      ],
      "metadata": {
        "id": "aj5c36K-yhpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve\n",
        "print(roc_auc_score(target_train, logreg.predict(data_train)))\n",
        "print(roc_auc_score(target_valid, logreg.predict(data_valid)))"
      ],
      "metadata": {
        "id": "E1aFb6ouyhne"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}